{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9912422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9912320/9912422 [00:55<00:00, 165634.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "32768it [00:00, 97459.85it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "  0%|          | 8192/1648877 [00:00<00:22, 72962.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 40960/1648877 [00:00<00:17, 94314.68it/s]\u001b[A\n",
      "  4%|▍         | 65536/1648877 [00:00<00:14, 111838.25it/s]\u001b[A\n",
      "  6%|▌         | 98304/1648877 [00:00<00:11, 138318.01it/s]\u001b[A\n",
      "  7%|▋         | 122880/1648877 [00:00<00:17, 85334.34it/s]\u001b[A\n",
      "  8%|▊         | 139264/1648877 [00:01<00:16, 88924.62it/s]\u001b[A\n",
      "  9%|▉         | 155648/1648877 [00:01<00:15, 97092.00it/s]\u001b[A\n",
      " 11%|█▏        | 188416/1648877 [00:01<00:15, 94382.68it/s]\u001b[A\n",
      " 13%|█▎        | 212992/1648877 [00:02<00:25, 55992.18it/s]\u001b[A\n",
      " 14%|█▍        | 229376/1648877 [00:02<00:21, 64594.70it/s]\u001b[A\n",
      " 15%|█▍        | 245760/1648877 [00:02<00:18, 76886.67it/s]\u001b[A\n",
      " 16%|█▌        | 262144/1648877 [00:02<00:15, 90640.10it/s]\u001b[A\n",
      " 17%|█▋        | 286720/1648877 [00:03<00:16, 81471.48it/s]\u001b[A\n",
      " 18%|█▊        | 303104/1648877 [00:03<00:14, 90719.20it/s]\u001b[A\n",
      " 20%|█▉        | 327680/1648877 [00:03<00:11, 110586.84it/s]\u001b[A\n",
      " 21%|██        | 344064/1648877 [00:03<00:11, 111320.50it/s]\u001b[A\n",
      " 22%|██▏       | 360448/1648877 [00:04<00:16, 76057.12it/s] \u001b[A\n",
      " 23%|██▎       | 376832/1648877 [00:04<00:14, 87339.75it/s]\u001b[A\n",
      " 24%|██▍       | 393216/1648877 [00:04<00:16, 75553.91it/s]\u001b[A\n",
      " 25%|██▍       | 409600/1648877 [00:04<00:14, 84169.30it/s]\u001b[A\n",
      " 26%|██▌       | 425984/1648877 [00:04<00:13, 90900.30it/s]\u001b[A\n",
      " 27%|██▋       | 450560/1648877 [00:04<00:11, 106612.74it/s]\u001b[A\n",
      " 29%|██▉       | 475136/1648877 [00:05<00:09, 121926.43it/s]\u001b[A\n",
      " 30%|██▉       | 491520/1648877 [00:05<00:10, 112125.25it/s]\u001b[A\n",
      " 32%|███▏      | 524288/1648877 [00:05<00:08, 130724.33it/s]\u001b[A\n",
      " 33%|███▎      | 548864/1648877 [00:05<00:07, 150397.48it/s]\u001b[A\n",
      " 35%|███▍      | 573440/1648877 [00:05<00:08, 121588.58it/s]\u001b[A\n",
      " 36%|███▌      | 589824/1648877 [00:05<00:08, 130395.60it/s]\u001b[A\n",
      " 37%|███▋      | 606208/1648877 [00:06<00:10, 97801.82it/s] \u001b[A\n",
      " 38%|███▊      | 630784/1648877 [00:06<00:08, 118572.62it/s]\u001b[A\n",
      " 39%|███▉      | 647168/1648877 [00:06<00:07, 127800.21it/s]\u001b[A\n",
      " 41%|████      | 671744/1648877 [00:06<00:07, 129991.79it/s]\u001b[A\n",
      " 43%|████▎     | 704512/1648877 [00:06<00:06, 142786.84it/s]\u001b[A\n",
      " 44%|████▎     | 720896/1648877 [00:07<00:21, 42887.12it/s] \u001b[A\n",
      " 45%|████▍     | 737280/1648877 [00:08<00:20, 44884.05it/s]\u001b[A\n",
      " 46%|████▌     | 753664/1648877 [00:08<00:26, 33384.69it/s]\u001b[A\n",
      " 48%|████▊     | 786432/1648877 [00:08<00:19, 45330.82it/s]\u001b[A\n",
      " 49%|████▉     | 811008/1648877 [00:09<00:14, 59705.13it/s]\u001b[A\n",
      " 51%|█████     | 835584/1648877 [00:09<00:11, 72029.59it/s]\u001b[A\n",
      " 52%|█████▏    | 851968/1648877 [00:09<00:09, 80415.94it/s]\u001b[A\n",
      " 53%|█████▎    | 868352/1648877 [00:09<00:13, 56670.86it/s]\u001b[A\n",
      " 54%|█████▎    | 884736/1648877 [00:10<00:15, 50692.29it/s]\u001b[A\n",
      " 55%|█████▍    | 901120/1648877 [00:10<00:16, 46507.59it/s]\u001b[A\n",
      " 57%|█████▋    | 933888/1648877 [00:10<00:11, 62315.71it/s]\u001b[A\n",
      " 59%|█████▊    | 966656/1648877 [00:10<00:08, 81922.00it/s]\u001b[A\n",
      " 60%|██████    | 991232/1648877 [00:11<00:07, 93019.04it/s]\u001b[A\n",
      " 62%|██████▏   | 1015808/1648877 [00:11<00:06, 99149.79it/s]\u001b[A\n",
      " 63%|██████▎   | 1032192/1648877 [00:11<00:08, 70225.95it/s]\u001b[A\n",
      " 64%|██████▎   | 1048576/1648877 [00:12<00:10, 59229.08it/s]\u001b[A\n",
      " 66%|██████▌   | 1081344/1648877 [00:12<00:07, 75796.33it/s]\u001b[A\n",
      " 69%|██████▊   | 1130496/1648877 [00:12<00:05, 99338.60it/s]\u001b[A\n",
      " 70%|███████   | 1155072/1648877 [00:12<00:04, 104575.12it/s]\u001b[A\n",
      " 72%|███████▏  | 1187840/1648877 [00:12<00:03, 128550.47it/s]\u001b[A\n",
      " 74%|███████▍  | 1220608/1648877 [00:12<00:02, 156076.94it/s]\u001b[A\n",
      " 76%|███████▌  | 1245184/1648877 [00:13<00:05, 77976.34it/s] \u001b[A\n",
      "9920512it [01:10, 165634.54it/s]                             [A\n",
      " 78%|███████▊  | 1294336/1648877 [00:14<00:04, 71002.33it/s]\u001b[A\n",
      " 79%|███████▉  | 1310720/1648877 [00:14<00:06, 55074.56it/s]\u001b[A\n",
      " 81%|████████▏ | 1343488/1648877 [00:14<00:04, 70287.08it/s]\u001b[A\n",
      " 84%|████████▍ | 1384448/1648877 [00:14<00:02, 91227.40it/s]\u001b[A\n",
      " 85%|████████▌ | 1409024/1648877 [00:15<00:02, 80855.30it/s]\u001b[A\n",
      " 86%|████████▋ | 1425408/1648877 [00:16<00:06, 34519.50it/s]\u001b[A\n",
      " 87%|████████▋ | 1441792/1648877 [00:17<00:07, 27319.56it/s]\u001b[A\n",
      " 88%|████████▊ | 1458176/1648877 [00:17<00:06, 30925.57it/s]\u001b[A\n",
      " 89%|████████▉ | 1466368/1648877 [00:17<00:04, 37950.88it/s]\u001b[A\n",
      " 89%|████████▉ | 1474560/1648877 [00:17<00:03, 44110.54it/s]\u001b[A\n",
      " 90%|████████▉ | 1482752/1648877 [00:17<00:03, 49831.39it/s]\u001b[A\n",
      " 91%|█████████ | 1499136/1648877 [00:18<00:02, 62569.94it/s]\u001b[A\n",
      " 93%|█████████▎| 1531904/1648877 [00:18<00:01, 82311.62it/s]\u001b[A\n",
      " 94%|█████████▍| 1556480/1648877 [00:18<00:01, 72149.68it/s]\u001b[A\n",
      " 95%|█████████▌| 1572864/1648877 [00:18<00:01, 62353.14it/s]\u001b[A\n",
      " 96%|█████████▋| 1589248/1648877 [00:19<00:00, 74793.37it/s]\u001b[A\n",
      " 97%|█████████▋| 1605632/1648877 [00:19<00:00, 86789.51it/s]\u001b[A\n",
      " 98%|█████████▊| 1622016/1648877 [00:19<00:00, 100041.67it/s]\u001b[A\n",
      "100%|█████████▉| 1646592/1648877 [00:19<00:00, 117933.03it/s]\u001b[A\n",
      "\n",
      "8192it [00:00, 223963.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#download data to the local work directory. convert to torch tensors\n",
    "train = datasets.MNIST(\"\", train=True, download = True,\n",
    "                       transform = transforms.Compose([transforms.ToTensor()]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1654784it [00:33, 117933.03it/s]                             \u001b[A"
     ]
    }
   ],
   "source": [
    "test = datasets.MNIST(\"\", train=False, download = True,\n",
    "                       transform = transforms.Compose([transforms.ToTensor()]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: \n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data, batch_size = how many datapoints to be passed for one opt step\n",
    "# to the model, \n",
    "trainset = torch.utils.data.DataLoader(train, batch_size= 10, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torch.utils.data.DataLoader(test, batch_size= 10, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([8, 3, 1, 2, 2, 9, 6, 4, 8, 5])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 3, 1, 2, 2, 9, 6, 4, 8, 5])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x[0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64) #fully connected layer, input flattened 28*28 image\n",
    "        self.fc2 = nn.Linear(64,64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):  #what to do with data in these layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)   #dim=1 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "o = optim.Adam(mynet.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2132, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0947, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0117, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for data in trainset:\n",
    "        X,y = data\n",
    "        mynet.zero_grad()\n",
    "        output = mynet(X.view(-1,28*28))\n",
    "        loss = F.nll_loss(output,y)\n",
    "        loss.backward()\n",
    "        o.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n",
       " tensor([2, 7, 2, 2, 6, 1, 3, 0, 2, 8]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(mynet(X[1].view(-1,28*28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2584e+01, -1.7169e+01, -1.1706e+01, -1.4992e+01, -2.8916e+01,\n",
       "         -2.4873e+01, -3.3822e+01, -8.5830e-06, -2.3508e+01, -1.9669e+01]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynet(X[1].view(-1,28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9782666666666666\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "t = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X,y = data\n",
    "        output = mynet(X.view(-1,784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                c+=1\n",
    "            t+=1\n",
    "print(c/t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev1 = qml.device('default.qubit', wires=1)\n",
    "\n",
    "# define neural network\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, classifier, n_wire):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.classifier = classifier\n",
    "        self.n_wire = n_wire\n",
    "        self.phi = torch.tensor(0.011, requires_grad = True)\n",
    "        self.theta = torch.tensor(0.012, requires_grad = True)\n",
    "        \n",
    "    def forward(self):\n",
    "        print(self.phi,self.theta)\n",
    "\n",
    "        @qml.qnode(dev1, interface='torch')\n",
    "        def circuit(*params):\n",
    "            self.classifier(*params)\n",
    "            return qml.expval.PauliZ(0)\n",
    "\n",
    "        return circuit(self.phi, self.theta)\n",
    "\n",
    "# define custom classifiers\n",
    "\n",
    "def test_rot(phi, theta):\n",
    "    qml.RX(phi, wires=0)\n",
    "    qml.RY(theta, wires=0)\n",
    "\n",
    "# perform the optimization\n",
    "\n",
    "testcl = NeuralNet(test_rot, 1)\n",
    "opt = torch.optim.Adam([testcl.phi, testcl.theta], lr = 0.1) \n",
    "\n",
    "for i in range(400):\n",
    "    opt.zero_grad()\n",
    "    output = testcl()\n",
    "    loss = output - 1\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
