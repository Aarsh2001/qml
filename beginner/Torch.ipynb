{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9912422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9912320/9912422 [00:55<00:00, 165634.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "32768it [00:00, 97459.85it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "  0%|          | 8192/1648877 [00:00<00:22, 72962.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 40960/1648877 [00:00<00:17, 94314.68it/s]\u001b[A\n",
      "  4%|▍         | 65536/1648877 [00:00<00:14, 111838.25it/s]\u001b[A\n",
      "  6%|▌         | 98304/1648877 [00:00<00:11, 138318.01it/s]\u001b[A\n",
      "  7%|▋         | 122880/1648877 [00:00<00:17, 85334.34it/s]\u001b[A\n",
      "  8%|▊         | 139264/1648877 [00:01<00:16, 88924.62it/s]\u001b[A\n",
      "  9%|▉         | 155648/1648877 [00:01<00:15, 97092.00it/s]\u001b[A\n",
      " 11%|█▏        | 188416/1648877 [00:01<00:15, 94382.68it/s]\u001b[A\n",
      " 13%|█▎        | 212992/1648877 [00:02<00:25, 55992.18it/s]\u001b[A\n",
      " 14%|█▍        | 229376/1648877 [00:02<00:21, 64594.70it/s]\u001b[A\n",
      " 15%|█▍        | 245760/1648877 [00:02<00:18, 76886.67it/s]\u001b[A\n",
      " 16%|█▌        | 262144/1648877 [00:02<00:15, 90640.10it/s]\u001b[A\n",
      " 17%|█▋        | 286720/1648877 [00:03<00:16, 81471.48it/s]\u001b[A\n",
      " 18%|█▊        | 303104/1648877 [00:03<00:14, 90719.20it/s]\u001b[A\n",
      " 20%|█▉        | 327680/1648877 [00:03<00:11, 110586.84it/s]\u001b[A\n",
      " 21%|██        | 344064/1648877 [00:03<00:11, 111320.50it/s]\u001b[A\n",
      " 22%|██▏       | 360448/1648877 [00:04<00:16, 76057.12it/s] \u001b[A\n",
      " 23%|██▎       | 376832/1648877 [00:04<00:14, 87339.75it/s]\u001b[A\n",
      " 24%|██▍       | 393216/1648877 [00:04<00:16, 75553.91it/s]\u001b[A\n",
      " 25%|██▍       | 409600/1648877 [00:04<00:14, 84169.30it/s]\u001b[A\n",
      " 26%|██▌       | 425984/1648877 [00:04<00:13, 90900.30it/s]\u001b[A\n",
      " 27%|██▋       | 450560/1648877 [00:04<00:11, 106612.74it/s]\u001b[A\n",
      " 29%|██▉       | 475136/1648877 [00:05<00:09, 121926.43it/s]\u001b[A\n",
      " 30%|██▉       | 491520/1648877 [00:05<00:10, 112125.25it/s]\u001b[A\n",
      " 32%|███▏      | 524288/1648877 [00:05<00:08, 130724.33it/s]\u001b[A\n",
      " 33%|███▎      | 548864/1648877 [00:05<00:07, 150397.48it/s]\u001b[A\n",
      " 35%|███▍      | 573440/1648877 [00:05<00:08, 121588.58it/s]\u001b[A\n",
      " 36%|███▌      | 589824/1648877 [00:05<00:08, 130395.60it/s]\u001b[A\n",
      " 37%|███▋      | 606208/1648877 [00:06<00:10, 97801.82it/s] \u001b[A\n",
      " 38%|███▊      | 630784/1648877 [00:06<00:08, 118572.62it/s]\u001b[A\n",
      " 39%|███▉      | 647168/1648877 [00:06<00:07, 127800.21it/s]\u001b[A\n",
      " 41%|████      | 671744/1648877 [00:06<00:07, 129991.79it/s]\u001b[A\n",
      " 43%|████▎     | 704512/1648877 [00:06<00:06, 142786.84it/s]\u001b[A\n",
      " 44%|████▎     | 720896/1648877 [00:07<00:21, 42887.12it/s] \u001b[A\n",
      " 45%|████▍     | 737280/1648877 [00:08<00:20, 44884.05it/s]\u001b[A\n",
      " 46%|████▌     | 753664/1648877 [00:08<00:26, 33384.69it/s]\u001b[A\n",
      " 48%|████▊     | 786432/1648877 [00:08<00:19, 45330.82it/s]\u001b[A\n",
      " 49%|████▉     | 811008/1648877 [00:09<00:14, 59705.13it/s]\u001b[A\n",
      " 51%|█████     | 835584/1648877 [00:09<00:11, 72029.59it/s]\u001b[A\n",
      " 52%|█████▏    | 851968/1648877 [00:09<00:09, 80415.94it/s]\u001b[A\n",
      " 53%|█████▎    | 868352/1648877 [00:09<00:13, 56670.86it/s]\u001b[A\n",
      " 54%|█████▎    | 884736/1648877 [00:10<00:15, 50692.29it/s]\u001b[A\n",
      " 55%|█████▍    | 901120/1648877 [00:10<00:16, 46507.59it/s]\u001b[A\n",
      " 57%|█████▋    | 933888/1648877 [00:10<00:11, 62315.71it/s]\u001b[A\n",
      " 59%|█████▊    | 966656/1648877 [00:10<00:08, 81922.00it/s]\u001b[A\n",
      " 60%|██████    | 991232/1648877 [00:11<00:07, 93019.04it/s]\u001b[A\n",
      " 62%|██████▏   | 1015808/1648877 [00:11<00:06, 99149.79it/s]\u001b[A\n",
      " 63%|██████▎   | 1032192/1648877 [00:11<00:08, 70225.95it/s]\u001b[A\n",
      " 64%|██████▎   | 1048576/1648877 [00:12<00:10, 59229.08it/s]\u001b[A\n",
      " 66%|██████▌   | 1081344/1648877 [00:12<00:07, 75796.33it/s]\u001b[A\n",
      " 69%|██████▊   | 1130496/1648877 [00:12<00:05, 99338.60it/s]\u001b[A\n",
      " 70%|███████   | 1155072/1648877 [00:12<00:04, 104575.12it/s]\u001b[A\n",
      " 72%|███████▏  | 1187840/1648877 [00:12<00:03, 128550.47it/s]\u001b[A\n",
      " 74%|███████▍  | 1220608/1648877 [00:12<00:02, 156076.94it/s]\u001b[A\n",
      " 76%|███████▌  | 1245184/1648877 [00:13<00:05, 77976.34it/s] \u001b[A\n",
      "9920512it [01:10, 165634.54it/s]                             [A\n",
      " 78%|███████▊  | 1294336/1648877 [00:14<00:04, 71002.33it/s]\u001b[A\n",
      " 79%|███████▉  | 1310720/1648877 [00:14<00:06, 55074.56it/s]\u001b[A\n",
      " 81%|████████▏ | 1343488/1648877 [00:14<00:04, 70287.08it/s]\u001b[A\n",
      " 84%|████████▍ | 1384448/1648877 [00:14<00:02, 91227.40it/s]\u001b[A\n",
      " 85%|████████▌ | 1409024/1648877 [00:15<00:02, 80855.30it/s]\u001b[A\n",
      " 86%|████████▋ | 1425408/1648877 [00:16<00:06, 34519.50it/s]\u001b[A\n",
      " 87%|████████▋ | 1441792/1648877 [00:17<00:07, 27319.56it/s]\u001b[A\n",
      " 88%|████████▊ | 1458176/1648877 [00:17<00:06, 30925.57it/s]\u001b[A\n",
      " 89%|████████▉ | 1466368/1648877 [00:17<00:04, 37950.88it/s]\u001b[A\n",
      " 89%|████████▉ | 1474560/1648877 [00:17<00:03, 44110.54it/s]\u001b[A\n",
      " 90%|████████▉ | 1482752/1648877 [00:17<00:03, 49831.39it/s]\u001b[A\n",
      " 91%|█████████ | 1499136/1648877 [00:18<00:02, 62569.94it/s]\u001b[A\n",
      " 93%|█████████▎| 1531904/1648877 [00:18<00:01, 82311.62it/s]\u001b[A\n",
      " 94%|█████████▍| 1556480/1648877 [00:18<00:01, 72149.68it/s]\u001b[A\n",
      " 95%|█████████▌| 1572864/1648877 [00:18<00:01, 62353.14it/s]\u001b[A\n",
      " 96%|█████████▋| 1589248/1648877 [00:19<00:00, 74793.37it/s]\u001b[A\n",
      " 97%|█████████▋| 1605632/1648877 [00:19<00:00, 86789.51it/s]\u001b[A\n",
      " 98%|█████████▊| 1622016/1648877 [00:19<00:00, 100041.67it/s]\u001b[A\n",
      "100%|█████████▉| 1646592/1648877 [00:19<00:00, 117933.03it/s]\u001b[A\n",
      "\n",
      "8192it [00:00, 223963.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#download data to the local work directory. convert to torch tensors\n",
    "train = datasets.MNIST(\"\", train=True, download = True,\n",
    "                       transform = transforms.Compose([transforms.ToTensor()]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1654784it [00:33, 117933.03it/s]                             \u001b[A"
     ]
    }
   ],
   "source": [
    "test = datasets.MNIST(\"\", train=False, download = True,\n",
    "                       transform = transforms.Compose([transforms.ToTensor()]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: \n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fa774a0d438>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load training data, batch_size = how many datapoints to be passed for one opt step\n",
    "# to the model, \n",
    "trainset = torch.utils.data.DataLoader(train, batch_size= 1, shuffle= True)\n",
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torch.utils.data.DataLoader(test, batch_size= 1, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.2471, 1.0000, 0.2745, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.6784, 0.9961, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.7725, 0.9961, 0.8824, 0.0549, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0784, 0.9451, 0.9725, 0.3255, 0.0314, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.1490, 0.9961, 0.7804, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.1020, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.4196, 0.9961, 0.3490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0392, 0.8314, 0.4824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.6980, 0.9961, 0.1922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.4549, 0.9961, 0.5804, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.7412, 0.9961, 0.1922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.5765, 0.9961, 0.5490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
      "           0.9804, 0.9137, 0.0745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1882,\n",
      "           0.9294, 0.9961, 0.2431, 0.0000, 0.0000, 0.0000, 0.0000, 0.1725,\n",
      "           0.9961, 0.8667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4549,\n",
      "           0.9961, 0.9373, 0.1137, 0.0235, 0.1294, 0.1490, 0.2510, 0.6980,\n",
      "           0.9961, 0.9137, 0.3451, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4549,\n",
      "           0.9961, 0.9961, 0.9961, 0.9020, 0.9961, 0.9961, 0.9882, 0.9137,\n",
      "           0.9961, 0.9961, 0.9020, 0.5608, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4549,\n",
      "           0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9333, 0.9059, 0.9961,\n",
      "           0.9961, 0.6706, 0.3176, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1020,\n",
      "           0.3804, 0.2745, 0.2235, 0.2235, 0.2235, 0.0824, 0.0353, 0.9961,\n",
      "           0.9490, 0.1255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2941, 0.9961,\n",
      "           0.8980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5216, 0.9961,\n",
      "           0.6275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6745, 0.9961,\n",
      "           0.2980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6745, 0.9961,\n",
      "           0.2549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9765, 0.9961,\n",
      "           0.2549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9961, 0.9725,\n",
      "           0.1725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "           0.0000, 0.0000, 0.0000, 0.0000]]]]), tensor([4])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x.view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64) #fully connected layer, input flattened 28*28 image\n",
    "        self.fc2 = nn.Linear(64,64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):  #what to do with data in these layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)   #dim=1 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "o = optim.Adam(mynet.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2132, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0947, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0117, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for data in trainset:\n",
    "        X,y = data\n",
    "        mynet.zero_grad()\n",
    "        output = mynet(X.view(-1,28*28))\n",
    "        loss = F.nll_loss(output,y)\n",
    "        loss.backward()\n",
    "        o.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n",
       " tensor([2, 7, 2, 2, 6, 1, 3, 0, 2, 8]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(mynet(X[1].view(-1,28*28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2584e+01, -1.7169e+01, -1.1706e+01, -1.4992e+01, -2.8916e+01,\n",
       "         -2.4873e+01, -3.3822e+01, -8.5830e-06, -2.3508e+01, -1.9669e+01]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynet(X[1].view(-1,28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9782666666666666\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "t = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X,y = data\n",
    "        output = mynet(X.view(-1,784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                c+=1\n",
    "            t+=1\n",
    "print(c/t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev1 = qml.device('default.qubit', wires=1)\n",
    "\n",
    "# define neural network\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, classifier, n_wire):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.classifier = classifier\n",
    "        self.n_wire = n_wire\n",
    "        self.phi = torch.tensor(0.011, requires_grad = True)\n",
    "        self.theta = torch.tensor(0.012, requires_grad = True)\n",
    "        \n",
    "    def forward(self):\n",
    "        print(self.phi,self.theta)\n",
    "\n",
    "        @qml.qnode(dev1, interface='torch')\n",
    "        def circuit(*params):\n",
    "            self.classifier(*params)\n",
    "            return qml.expval.PauliZ(0)\n",
    "\n",
    "        return circuit(self.phi, self.theta)\n",
    "\n",
    "# define custom classifiers\n",
    "\n",
    "def test_rot(phi, theta):\n",
    "    qml.RX(phi, wires=0)\n",
    "    qml.RY(theta, wires=0)\n",
    "\n",
    "# perform the optimization\n",
    "\n",
    "testcl = NeuralNet(test_rot, 1)\n",
    "opt = torch.optim.Adam([testcl.phi, testcl.theta], lr = 0.1) \n",
    "\n",
    "for i in range(400):\n",
    "    opt.zero_grad()\n",
    "    output = testcl()\n",
    "    loss = output - 1\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class access_one_image(Dataset):\n",
    "    def __init__(self, data):\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-92c0d56dc722>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccess_one_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "access_one_image(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
