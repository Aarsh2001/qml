{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class makedata(Dataset):\n",
    "    def __init__(self, col, n_feat, maximum):\n",
    "        self.col = col  #number of datapoints\n",
    "        self.n_feat = n_feat  #number of features\n",
    "        self.maximum = maximum  #increase the range of feature data\n",
    "        self.classes = 2   #number of classes\n",
    "\n",
    "        if col%2 != 0:\n",
    "            col = col+1\n",
    "            print(\"Making datasize an even number for ease: col =\", col)\n",
    "        \n",
    "        self.Xdata1 = torch.rand(col//2, n_feat)*maximum -0.4 \n",
    "        self.Xdata2 = torch.rand(col//2, n_feat)*-maximum +0.4\n",
    "        self.Xdata = torch.cat((self.Xdata1, self.Xdata2), dim=0)\n",
    "\n",
    "        self.Ydata = torch.cat((torch.full((col//2,), 1),torch.full((col//2,), -1)))       \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Ydata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.Xdata[idx],self.Ydata[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r =5\n",
    "data = makedata(100, 2, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tensor([[ 2.0112,  2.8493],\n",
      "        [ 0.7276,  0.9278],\n",
      "        [ 3.2682,  0.5031],\n",
      "        [ 1.3183,  2.9685],\n",
      "        [ 4.2772,  0.2010],\n",
      "        [ 3.8418,  1.3278],\n",
      "        [ 1.7914,  2.1299],\n",
      "        [ 3.5049,  2.7257],\n",
      "        [ 1.0015,  2.3032],\n",
      "        [-0.1458,  3.1430],\n",
      "        [ 3.9750,  3.5774],\n",
      "        [ 3.9428,  2.5406],\n",
      "        [-0.2464,  2.5712],\n",
      "        [ 1.0607,  3.9055],\n",
      "        [-0.0062,  3.0285],\n",
      "        [ 0.3978,  0.5115],\n",
      "        [-0.1678,  0.0636],\n",
      "        [ 1.5575,  2.7338],\n",
      "        [ 4.5279, -0.2458],\n",
      "        [ 3.7934,  0.6809],\n",
      "        [ 3.7855,  1.8603],\n",
      "        [ 2.6047, -0.3192],\n",
      "        [ 3.0447,  2.7204],\n",
      "        [ 0.4449,  1.6583],\n",
      "        [ 2.3399,  0.6076],\n",
      "        [ 4.4211,  2.4921],\n",
      "        [ 1.8463,  0.5386],\n",
      "        [ 4.0802, -0.0930],\n",
      "        [ 1.4225,  0.9076],\n",
      "        [-0.2298,  2.2302],\n",
      "        [ 4.4113,  1.4588],\n",
      "        [ 1.1817,  4.5766],\n",
      "        [ 3.4263,  2.2432],\n",
      "        [ 1.7959,  2.2175],\n",
      "        [ 3.5989,  3.9240],\n",
      "        [-0.2223,  4.5691],\n",
      "        [ 3.9629,  4.5421],\n",
      "        [ 2.8607,  3.5843],\n",
      "        [ 0.2377,  3.9463],\n",
      "        [ 2.8523,  1.4896],\n",
      "        [ 2.9747,  4.0356],\n",
      "        [ 1.6809,  3.2523],\n",
      "        [ 3.1588,  1.2725],\n",
      "        [ 3.6468,  1.8436],\n",
      "        [ 4.2777,  0.8031],\n",
      "        [ 3.2609,  0.1577],\n",
      "        [ 0.8096,  2.2431],\n",
      "        [ 1.4035,  3.7036],\n",
      "        [ 3.4307,  0.5229],\n",
      "        [ 2.8707,  2.8282]])\n",
      "tensor([[-1.8187,  0.1439],\n",
      "        [-3.2545, -1.0478],\n",
      "        [-2.8644, -0.0842],\n",
      "        [-0.8739, -3.2712],\n",
      "        [-4.1861, -3.5542],\n",
      "        [-1.8783, -3.2916],\n",
      "        [-1.5376, -1.1269],\n",
      "        [ 0.0577, -1.2591],\n",
      "        [-2.0775, -0.7072],\n",
      "        [ 0.2405, -3.6654],\n",
      "        [-2.4461,  0.2805],\n",
      "        [-0.8877, -2.7715],\n",
      "        [-1.1727, -1.5229],\n",
      "        [-1.0472, -1.2272],\n",
      "        [-3.4065, -3.0559],\n",
      "        [-2.0602, -0.6893],\n",
      "        [ 0.1483, -4.5747],\n",
      "        [-1.3940, -0.4735],\n",
      "        [-0.9502, -2.5031],\n",
      "        [-2.2256, -1.3152],\n",
      "        [-2.8690, -4.5136],\n",
      "        [-1.0170, -1.4635],\n",
      "        [-2.8059, -1.8805],\n",
      "        [-1.2126, -2.1886],\n",
      "        [-0.2870, -0.2402],\n",
      "        [-2.8889,  0.1590],\n",
      "        [-3.5528, -2.1682],\n",
      "        [-0.2103, -3.2735],\n",
      "        [-3.1952, -3.0128],\n",
      "        [-3.9466, -1.2423],\n",
      "        [-0.2213, -2.0092],\n",
      "        [-2.7354, -3.3975],\n",
      "        [-2.2633,  0.2142],\n",
      "        [-3.1073,  0.2764],\n",
      "        [ 0.3786, -2.5615],\n",
      "        [-3.8082, -2.4245],\n",
      "        [ 0.1903, -2.4042],\n",
      "        [-0.7473, -3.7021],\n",
      "        [-1.3843, -4.2571],\n",
      "        [-3.6516, -4.2322],\n",
      "        [-1.8519, -1.6451],\n",
      "        [-2.0245, -4.2723],\n",
      "        [-1.6027, -2.5770],\n",
      "        [-1.2119, -1.5005],\n",
      "        [ 0.1094, -1.4809],\n",
      "        [-1.3860, -0.1623],\n",
      "        [-3.6866, -0.9644],\n",
      "        [-4.3854, -4.2518],\n",
      "        [-4.5490, -1.6670],\n",
      "        [-2.4658, -2.7779]])\n",
      "tensor([[ 2.0112,  2.8493],\n",
      "        [ 0.7276,  0.9278],\n",
      "        [ 3.2682,  0.5031],\n",
      "        [ 1.3183,  2.9685],\n",
      "        [ 4.2772,  0.2010],\n",
      "        [ 3.8418,  1.3278],\n",
      "        [ 1.7914,  2.1299],\n",
      "        [ 3.5049,  2.7257],\n",
      "        [ 1.0015,  2.3032],\n",
      "        [-0.1458,  3.1430],\n",
      "        [ 3.9750,  3.5774],\n",
      "        [ 3.9428,  2.5406],\n",
      "        [-0.2464,  2.5712],\n",
      "        [ 1.0607,  3.9055],\n",
      "        [-0.0062,  3.0285],\n",
      "        [ 0.3978,  0.5115],\n",
      "        [-0.1678,  0.0636],\n",
      "        [ 1.5575,  2.7338],\n",
      "        [ 4.5279, -0.2458],\n",
      "        [ 3.7934,  0.6809],\n",
      "        [ 3.7855,  1.8603],\n",
      "        [ 2.6047, -0.3192],\n",
      "        [ 3.0447,  2.7204],\n",
      "        [ 0.4449,  1.6583],\n",
      "        [ 2.3399,  0.6076],\n",
      "        [ 4.4211,  2.4921],\n",
      "        [ 1.8463,  0.5386],\n",
      "        [ 4.0802, -0.0930],\n",
      "        [ 1.4225,  0.9076],\n",
      "        [-0.2298,  2.2302],\n",
      "        [ 4.4113,  1.4588],\n",
      "        [ 1.1817,  4.5766],\n",
      "        [ 3.4263,  2.2432],\n",
      "        [ 1.7959,  2.2175],\n",
      "        [ 3.5989,  3.9240],\n",
      "        [-0.2223,  4.5691],\n",
      "        [ 3.9629,  4.5421],\n",
      "        [ 2.8607,  3.5843],\n",
      "        [ 0.2377,  3.9463],\n",
      "        [ 2.8523,  1.4896],\n",
      "        [ 2.9747,  4.0356],\n",
      "        [ 1.6809,  3.2523],\n",
      "        [ 3.1588,  1.2725],\n",
      "        [ 3.6468,  1.8436],\n",
      "        [ 4.2777,  0.8031],\n",
      "        [ 3.2609,  0.1577],\n",
      "        [ 0.8096,  2.2431],\n",
      "        [ 1.4035,  3.7036],\n",
      "        [ 3.4307,  0.5229],\n",
      "        [ 2.8707,  2.8282],\n",
      "        [-1.8187,  0.1439],\n",
      "        [-3.2545, -1.0478],\n",
      "        [-2.8644, -0.0842],\n",
      "        [-0.8739, -3.2712],\n",
      "        [-4.1861, -3.5542],\n",
      "        [-1.8783, -3.2916],\n",
      "        [-1.5376, -1.1269],\n",
      "        [ 0.0577, -1.2591],\n",
      "        [-2.0775, -0.7072],\n",
      "        [ 0.2405, -3.6654],\n",
      "        [-2.4461,  0.2805],\n",
      "        [-0.8877, -2.7715],\n",
      "        [-1.1727, -1.5229],\n",
      "        [-1.0472, -1.2272],\n",
      "        [-3.4065, -3.0559],\n",
      "        [-2.0602, -0.6893],\n",
      "        [ 0.1483, -4.5747],\n",
      "        [-1.3940, -0.4735],\n",
      "        [-0.9502, -2.5031],\n",
      "        [-2.2256, -1.3152],\n",
      "        [-2.8690, -4.5136],\n",
      "        [-1.0170, -1.4635],\n",
      "        [-2.8059, -1.8805],\n",
      "        [-1.2126, -2.1886],\n",
      "        [-0.2870, -0.2402],\n",
      "        [-2.8889,  0.1590],\n",
      "        [-3.5528, -2.1682],\n",
      "        [-0.2103, -3.2735],\n",
      "        [-3.1952, -3.0128],\n",
      "        [-3.9466, -1.2423],\n",
      "        [-0.2213, -2.0092],\n",
      "        [-2.7354, -3.3975],\n",
      "        [-2.2633,  0.2142],\n",
      "        [-3.1073,  0.2764],\n",
      "        [ 0.3786, -2.5615],\n",
      "        [-3.8082, -2.4245],\n",
      "        [ 0.1903, -2.4042],\n",
      "        [-0.7473, -3.7021],\n",
      "        [-1.3843, -4.2571],\n",
      "        [-3.6516, -4.2322],\n",
      "        [-1.8519, -1.6451],\n",
      "        [-2.0245, -4.2723],\n",
      "        [-1.6027, -2.5770],\n",
      "        [-1.2119, -1.5005],\n",
      "        [ 0.1094, -1.4809],\n",
      "        [-1.3860, -0.1623],\n",
      "        [-3.6866, -0.9644],\n",
      "        [-4.3854, -4.2518],\n",
      "        [-4.5490, -1.6670],\n",
      "        [-2.4658, -2.7779]])\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1.])\n",
      "tensor([3.2682, 0.5031]) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data.Xdata1)\n",
    "print(data.Xdata2)\n",
    "print(data.Xdata)\n",
    "print(data.Ydata)\n",
    "x,y = data.__getitem__(2)\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.2256, -1.3152],\n",
      "        [ 2.3399,  0.6076],\n",
      "        [ 0.4449,  1.6583],\n",
      "        [-1.3843, -4.2571]])\n"
     ]
    }
   ],
   "source": [
    "data_batches = DataLoader(data, batch_size=4, shuffle=True)\n",
    "for d in data_batches:\n",
    "    x,y = d\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = (\"red\", \"blue\")\n",
    "groups = (\"class 1\", \"class 2\")\n",
    "\n",
    "#plt.xlim(-r+1,r+1)\n",
    "#plt.ylim(-r+1,r+1)\n",
    "plt.scatter(data.Xdata1[:,0], data.Xdata1[:,1], color=\"tab:red\", label= \"Class1\")\n",
    "plt.scatter(data.Xdata2[:,0], data.Xdata2[:,1], color=\"tab:blue\", label = \"Class2\")\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane.templates.embeddings import AmplitudeEmbedding\n",
    "\n",
    "def rlayer(W):\n",
    "    qml.Rot(W[0, 0], W[0, 1], W[0, 2], wires=0)\n",
    "    qml.Rot(W[1, 0], W[1, 1], W[1, 2], wires=1)\n",
    "    qml.CNOT(wires=[0,1])\n",
    "\n",
    "dev = qml.device('default.qubit', wires=2)\n",
    "\n",
    "@qml.qnode(dev, interface = 'torch')\n",
    "def circuit(weights, p=None):\n",
    "    AmplitudeEmbedding(p, wires=[0,1], pad=True, normalize=True)\n",
    "    rlayer(weights)\n",
    "    return qml.expval(qml.PauliZ(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(weights, x):   #predictions for one batch\n",
    "    pred = torch.empty(4,)    \n",
    "    for i in range(len(x)):\n",
    "        pred[i] = circuit(weights, p=x[i])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(weights, x, y):\n",
    "    loss = 0\n",
    "    pred = get_pred(weights,x)\n",
    "    loss = torch.sum(torch.abs(pred-y)**2)/len(y)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.7603, 1.7550, 2.5326],\n",
      "        [4.6162, 0.1840, 5.0257]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from math import pi\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(1)\n",
    "#weights_init = Variable((2*pi * torch.rand((2, 3), dtype=torch.float64)), requires_grad=True)\n",
    "weights_init = torch.rand((2, 3), requires_grad = True) * (2*pi)\n",
    "print(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1831, dtype=torch.float64, grad_fn=<_TorchQNodeBackward>)\n"
     ]
    }
   ],
   "source": [
    "test = torch.tensor([0.001, 0.004])\n",
    "\n",
    "print(circuit(weights_init, p=test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can't optimize a non-leaf Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7409ef1530cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mweights_init\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda3/lib/python3.7/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, momentum, dampening, weight_decay, nesterov)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdampening\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nesterov momentum requires a momentum and zero dampening\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda3/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda3/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36madd_param_group\u001b[0;34m(self, param_group)\u001b[0m\n\u001b[1;32m    200\u001b[0m                                 \"but one of the params is \" + torch.typename(param))\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"can't optimize a non-leaf Tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: can't optimize a non-leaf Tensor"
     ]
    }
   ],
   "source": [
    "weights = [weights_init]\n",
    "opt = torch.optim.SGD(weights, lr = 0.1)\n",
    "\n",
    "for step in range(50):\n",
    "    for d in data_batches:\n",
    "        x,y = d\n",
    "        opt.zero_grad()\n",
    "        loss = get_loss(weights, x, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    print(step, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
